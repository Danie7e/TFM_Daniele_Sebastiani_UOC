{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2lkQycbADFC",
        "outputId": "6bbec2f5-49bb-47c6-df9e-292d67932413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vktNNZNyAC4Y",
        "outputId": "2a88caca-8bb5-40ae-a2fd-fd34ddf1c146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70378 Index(['PDB_entry_id', 'Classification', 'Organism', 'Uniprot_id', 'Ligand_id',\n",
            "       'Ligand_InChi', 'Experimental_method', 'Resolution',\n",
            "       'Adding_Classification', 'Affinity', 'Coordenadas', 'Ligand_smiles',\n",
            "       'Mol_Weight', 'n_atoms', 'Nombre', 'Ligand_Class', 'Pfam_Names',\n",
            "       'SUPFAM_Names', 'intepro_class'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#@title Abrir los dataframes\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/TFM/T3/Red_Neuronal/intento2\"\n",
        "input_file_df_final = os.path.join(input_folder, \"df_FINAL_tot.csv\")\n",
        "df_harm = pd.read_csv(input_file_df_final, sep = ',')\n",
        "print(df_harm.shape[0],df_harm.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji3G1Y-bAC16",
        "outputId": "53157a91-f364-4caa-bb65-fd70913c9302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70378 Index(['instancia', 'Ligand_smiles', 'smiles_neg', 'tanimoto', 'usrr_sim',\n",
            "       'USR_neg_1', 'USR_neg_2', 'USR_neg_3', 'USR_neg_4', 'USR_neg_5',\n",
            "       'USR_neg_6', 'USR_neg_7', 'USR_neg_8', 'USR_neg_9', 'USR_neg_10',\n",
            "       'USR_neg_11', 'USR_neg_12'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "input_neg_dec = os.path.join(input_folder, \"decoys_full.csv\")\n",
        "df_neg_dec = pd.read_csv(input_neg_dec, sep = ',')\n",
        "print(df_neg_dec.shape[0],df_neg_dec.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RPpG4UfACy5"
      },
      "outputs": [],
      "source": [
        "df_pos = df_harm[['Nombre','Ligand_smiles']]\n",
        "df_pos = df_pos.rename(columns={'Nombre':'instancia'})\n",
        "df_neg = df_neg_dec[['instancia','smiles_neg']]\n",
        "df_neg = df_neg.rename(columns={'smiles_neg':'Ligand_smiles'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azeSDq-bACwa"
      },
      "outputs": [],
      "source": [
        "df_pos['instancia'] = df_pos['instancia'].astype(str) + '_positive'\n",
        "df_neg['instancia'] = df_neg['instancia'].astype(str) + '_negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3R-JpkEACth"
      },
      "outputs": [],
      "source": [
        "df_total = pd.concat([df_pos, df_neg], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQE-dcqc_Yvp",
        "outputId": "a7ffcd60-12c0-4aa9-ae1f-9e96e8d28af0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "140756"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_total.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nBmB0ArSAmtQ",
        "outputId": "1f94b95b-fe57-4955-a2b4-48a04f493195"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sw-7RvvxBLuB",
        "outputId": "f851f023-71f1-42f2-a925-843223393a3b"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4c9JOIp_SFG",
        "outputId": "9f89dd05-8acf-48c1-a325-15c347885d69"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 0) Funciones para grafo PyG\n",
        "# ----------------------------------------------------------\n",
        "def one_hot_encoding(x, choices):\n",
        "    if x not in choices: x = choices[-1]\n",
        "    return [int(x==c) for c in choices]\n",
        "\n",
        "def atom_features(atom):\n",
        "    feats = [\n",
        "      atom.GetAtomicNum(),\n",
        "      atom.GetDegree(),\n",
        "      atom.GetFormalCharge(),\n",
        "      atom.GetTotalNumHs(),\n",
        "      int(atom.GetIsAromatic()),\n",
        "      int(atom.IsInRing())\n",
        "    ]\n",
        "    hybs = [Chem.HybridizationType.SP, Chem.HybridizationType.SP2,\n",
        "            Chem.HybridizationType.SP3, Chem.HybridizationType.SP3D,\n",
        "            Chem.HybridizationType.SP3D2, Chem.HybridizationType.UNSPECIFIED]\n",
        "    feats += one_hot_encoding(atom.GetHybridization(), hybs)\n",
        "    chirs = [Chem.ChiralType.CHI_UNSPECIFIED,\n",
        "             Chem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
        "             Chem.ChiralType.CHI_TETRAHEDRAL_CCW]\n",
        "    feats += one_hot_encoding(atom.GetChiralTag(), chirs)\n",
        "    return feats\n",
        "\n",
        "def mol_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(f\"SMILES inválido: {smiles}\")\n",
        "    x = torch.tensor([atom_features(a) for a in mol.GetAtoms()], dtype=torch.float)\n",
        "    ei, ea = [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i,j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        bt = b.GetBondTypeAsDouble()\n",
        "        conj, ring = int(b.GetIsConjugated()), int(b.IsInRing())\n",
        "        ei += [[i,j],[j,i]]\n",
        "        ea += [[bt,conj,ring],[bt,conj,ring]]\n",
        "    edge_index = torch.tensor(ei, dtype=torch.long).t().contiguous()\n",
        "    edge_attr  = torch.tensor(ea, dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "class SMILESDataset(InMemoryDataset):\n",
        "    def __init__(self, data_list):\n",
        "        super().__init__('.', None, None, None)\n",
        "        self.data, self.slices = self.collate(data_list)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1) Cálculo fingerprint de Morgan (128 bits)\n",
        "# ----------------------------------------------------------\n",
        "def smiles_to_morgan(smiles, radius=2, nBits=128):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(f\"SMILES inválido: {smiles}\")\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
        "    arr = np.zeros((nBits,), dtype=float)\n",
        "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "    return arr\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2) Definición del modelo de pre-entrenamiento\n",
        "# ----------------------------------------------------------\n",
        "class GNNPretrain(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim=128, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels,  hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim,   hidden_dim)\n",
        "        self.decoder = torch.nn.Linear(hidden_dim, out_dim)\n",
        "    def forward(self, data):\n",
        "        x, ei, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, ei))\n",
        "        x = F.relu(self.conv2(x, ei))\n",
        "        hg = global_mean_pool(x, batch)    # (batch, hidden_dim)\n",
        "        return self.decoder(hg)            # (batch, out_dim)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3) Cargar SMILES y preparar DataList\n",
        "# ----------------------------------------------------------\n",
        "#df = pd.read_csv(\"/content/drive/MyDrive/TFM/T3/Archivos/df_FINAL_tot.csv\")\n",
        "df = df_total\n",
        "if 'Ligand_smiles' not in df.columns:\n",
        "    raise ValueError(\"Falta columna 'Ligand_smiles' en el CSV\")\n",
        "smiles_list = df['Ligand_smiles'].dropna().unique().tolist()\n",
        "print(f\"{len(smiles_list)} SMILES únicos encontrados\")\n",
        "\n",
        "data_list = []\n",
        "for smi in smiles_list:\n",
        "    try:\n",
        "        g = mol_to_graph(smi)\n",
        "        fp = smiles_to_morgan(smi)                     # np.array (128,)\n",
        "        g.y = torch.tensor(fp, dtype=torch.float).unsqueeze(0)  # shape (1,128)\n",
        "        data_list.append(g)\n",
        "    except Exception as e:\n",
        "        print(f\"  - Omitido {smi}: {e}\")\n",
        "\n",
        "print(f\"{len(data_list)} grafos + fingerprints listos\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4) División train/val y DataLoaders\n",
        "# ----------------------------------------------------------\n",
        "idx = list(range(len(data_list)))\n",
        "i_train, i_val = train_test_split(idx, test_size=0.2, random_state=42)\n",
        "train_ds = SMILESDataset([data_list[i] for i in i_train])\n",
        "val_ds   = SMILESDataset([data_list[i] for i in i_val])\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 5) Instanciar modelo y optimizador\n",
        "# ----------------------------------------------------------\n",
        "in_ch = train_ds[0].x.shape[1]\n",
        "model = GNNPretrain(in_channels=in_ch, hidden_dim=128, out_dim=128)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "best_val = float('inf')\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 6) Bucle de pre-entrenamiento\n",
        "# ----------------------------------------------------------\n",
        "for epoch in range(1, 51):\n",
        "    model.train()\n",
        "    lt = 0\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        pred = model(batch)               # (B,128)\n",
        "        loss = F.mse_loss(pred, batch.y)  # both (B,128)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        lt += loss.item()\n",
        "    lt /= len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    lv = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            lv += F.mse_loss(model(batch), batch.y).item()\n",
        "    lv /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} — train_loss {lt:.4f} | val_loss {lv:.4f}\")\n",
        "    if lv < best_val:\n",
        "        best_val = lv\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/TFM/T3/Red_Neuronal/intento2/gnn_weights.pth\")\n",
        "        print(\" → Guardados mejores pesos en gnn_weights.pth\")\n",
        "\n",
        "print(\"Pre-entrenamiento completado\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0VkBIGtBuAw",
        "outputId": "c5f529cb-e819-48a7-bf91-6325a4db3141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Embeddings por instancia guardados en: /content/drive/MyDrive/TFM/T3/Archivos/df_embeddings_ligandos_instancia_preentrenado.csv\n"
          ]
        }
      ],
      "source": [
        "#@title Generar Embedding ligandos\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Funciones y clases\n",
        "# -------------------------------\n",
        "def one_hot_encoding(x, choices):\n",
        "    if x not in choices: x = choices[-1]\n",
        "    return [int(x == c) for c in choices]\n",
        "\n",
        "def atom_features(atom: Chem.rdchem.Atom) -> list:\n",
        "    feats = [\n",
        "        atom.GetAtomicNum(),\n",
        "        atom.GetDegree(),\n",
        "        atom.GetFormalCharge(),\n",
        "        atom.GetTotalNumHs(),\n",
        "        int(atom.GetIsAromatic()),\n",
        "        int(atom.IsInRing())\n",
        "    ]\n",
        "    hybrid_types = [\n",
        "        Chem.HybridizationType.SP, Chem.HybridizationType.SP2,\n",
        "        Chem.HybridizationType.SP3, Chem.HybridizationType.SP3D,\n",
        "        Chem.HybridizationType.SP3D2, Chem.HybridizationType.UNSPECIFIED\n",
        "    ]\n",
        "    feats += one_hot_encoding(atom.GetHybridization(), hybrid_types)\n",
        "    chiral_types = [\n",
        "        Chem.ChiralType.CHI_UNSPECIFIED,\n",
        "        Chem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
        "        Chem.ChiralType.CHI_TETRAHEDRAL_CCW\n",
        "    ]\n",
        "    feats += one_hot_encoding(atom.GetChiralTag(), chiral_types)\n",
        "    return feats\n",
        "\n",
        "def mol_to_graph(smiles: str) -> Data:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(f\"Invalid SMILES: {smiles}\")\n",
        "    x = torch.tensor([atom_features(a) for a in mol.GetAtoms()], dtype=torch.float)\n",
        "    edge_index, edge_attr = [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        bt = b.GetBondTypeAsDouble()\n",
        "        conj, ring = int(b.GetIsConjugated()), int(b.IsInRing())\n",
        "        edge_index += [[i, j], [j, i]]\n",
        "        edge_attr  += [[bt, conj, ring], [bt, conj, ring]]\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr  = torch.tensor(edge_attr,  dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "class SMILESDataset(InMemoryDataset):\n",
        "    def __init__(self, data_list):\n",
        "        super().__init__('.', None, None, None)\n",
        "        self.data, self.slices = self.collate(data_list)\n",
        "\n",
        "class GNNEmbedding(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "    def forward(self, data):\n",
        "        x, ei, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, ei))\n",
        "        x = F.relu(self.conv2(x, ei))\n",
        "        return global_mean_pool(x, batch)\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Cargar datos\n",
        "# -------------------------------\n",
        "df = df_total  # tu DataFrame en memoria\n",
        "assert 'instancia' in df.columns and 'Ligand_smiles' in df.columns\n",
        "\n",
        "# -------------------------------\n",
        "# 3) Preparar grafos por instancia\n",
        "# -------------------------------\n",
        "data_list = []\n",
        "instances = []\n",
        "for _, row in df.iterrows():\n",
        "    inst = row['instancia']\n",
        "    smi = row['Ligand_smiles']\n",
        "    try:\n",
        "        g = mol_to_graph(smi)\n",
        "        g.instancia = inst\n",
        "        data_list.append(g)\n",
        "        instances.append(inst)\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "# -------------------------------\n",
        "# 4) Dataset y DataLoader\n",
        "# -------------------------------\n",
        "dataset = SMILESDataset(data_list)\n",
        "loader  = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# -------------------------------\n",
        "# 5) Cargar pesos pre-entrenados (filtrando decoder)\n",
        "# -------------------------------\n",
        "gnn_weights = \"/content/drive/MyDrive/TFM/T3/Red_Neuronal/intento2/gnn_weights.pth\"\n",
        "in_ch = dataset[0].x.shape[1]\n",
        "model = GNNEmbedding(in_channels=in_ch, hidden_dim=128)\n",
        "\n",
        "# Cargar state_dict completo\n",
        "pretrained = torch.load(gnn_weights, map_location='cpu')\n",
        "# Filtrar solo las claves que existen en nuestro modelo\n",
        "model_dict = model.state_dict()\n",
        "filtered = {k: v for k, v in pretrained.items() if k in model_dict}\n",
        "model_dict.update(filtered)\n",
        "model.load_state_dict(model_dict)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# -------------------------------\n",
        "# 6) Calcular embeddings\n",
        "# -------------------------------\n",
        "all_emb = []\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        emb = model(batch)  # (batch_size, 128)\n",
        "        all_emb.append(emb)\n",
        "\n",
        "embeddings = torch.cat(all_emb, dim=0).numpy()\n",
        "\n",
        "# -------------------------------\n",
        "# 7) DataFrame final y guardado\n",
        "# -------------------------------\n",
        "col_names = [f\"emb_lig_{i}\" for i in range(128)]\n",
        "df_emb = pd.DataFrame(embeddings, columns=col_names)\n",
        "df_emb.insert(0, 'instancia', instances)\n",
        "\n",
        "out_path = \"/content/drive/MyDrive/TFM/T3/Archivos/df_embeddings_ligandos_instancia_preentrenado.csv\"\n",
        "df_emb.to_csv(out_path, index=False)\n",
        "print(\"Embeddings por instancia guardados en:\", out_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
