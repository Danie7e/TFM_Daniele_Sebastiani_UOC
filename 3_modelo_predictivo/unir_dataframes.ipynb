{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2lkQycbADFC",
        "outputId": "6bbec2f5-49bb-47c6-df9e-292d67932413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Abrir los dataframes\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/TFM/T3/Archivos\"\n",
        "\n",
        "# Dataframe Final (positivos)\n",
        "\n",
        "input_file_df_final = os.path.join(input_folder, \"df_FINAL_tot.csv\")\n",
        "df_final_positive = pd.read_csv(input_file_df_final, sep = ',')\n",
        "\n",
        "# Dataframe decoys negativos\n",
        "\n",
        "input_file_decoys_negativos = os.path.join(input_folder, \"decoys_full.csv\")\n",
        "df_decoys_negativos = pd.read_csv(input_file_decoys_negativos, sep = ',')\n",
        "df_decoys_negativos = df_decoys_negativos.dropna()\n",
        "\n",
        "# Embedding ligandos positivos y negativos\n",
        "\n",
        "input_file_emb_ligandos = \"/content/drive/MyDrive/TFM/T3/Archivos/df_embeddings_ligandos_instancia_preentrenado.csv\"\n",
        "df_emb_ligandos = pd.read_csv(input_file_emb_ligandos, sep = ',')\n",
        "\n",
        "# Embedding de las proteínas\n",
        "\n",
        "input_file_emb_proteinas = os.path.join(input_folder, \"embeddings_proteinas_ESM2.csv\")\n",
        "df_emb_proteinas = pd.read_csv(input_file_emb_proteinas, sep = ',')\n",
        "\n",
        "# USR sitios\n",
        "df_usr_sitio = pd.read_csv(\"/content/drive/MyDrive/TFM/T3/Archivos/df_usr_sitio.csv\", sep=',')\n",
        "\n",
        "# USR ligandos\n",
        "input_file_df_ligand_smiles_USR = os.path.join(input_folder, \"df_ligand_smiles_USR.csv\")\n",
        "df_ligand_smiles_USR = pd.read_csv(input_file_df_ligand_smiles_USR, sep = ',')\n",
        "df_ligand_smiles_USR.shape[0]"
      ],
      "metadata": {
        "id": "SO4bjh3hYzaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos = df_final_positive[['Nombre','PDB_entry_id','Ligand_smiles']]\n",
        "df_pos = df_pos.rename(columns={'Nombre':'instancia'})"
      ],
      "metadata": {
        "id": "Vd6COWmuY1aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Función auxiliar para extraer \"PDBID_CHAIN\" de la instancia\n",
        "def extract_pdb_chain(inst):\n",
        "    pdb, _, chain, *_ = inst.split('_')\n",
        "    return f\"{pdb}_{chain}\"\n",
        "\n",
        "# 1) Preparar positivos\n",
        "df_pos2 = df_pos.copy()\n",
        "df_pos2['instancia'] = df_pos2['instancia'] + '_positive'\n",
        "df_pos2['Label']     = 1\n",
        "df_pos2['PDB_chain'] = df_pos2['instancia'].apply(extract_pdb_chain)\n",
        "\n",
        "# 2) Preparar negativos\n",
        "df_neg2 = df_decoys_negativos.copy()\n",
        "df_neg2['instancia'] = df_neg2['instancia'] + '_negative'\n",
        "df_neg2['Label']     = 0\n",
        "# renombrar USR_neg_i → USR_i_ligando\n",
        "df_neg2 = df_neg2.rename(columns={f'USR_neg_{i}': f'USR_{i}_ligando' for i in range(1, 13)})\n",
        "df_neg2['PDB_chain'] = df_neg2['instancia'].apply(extract_pdb_chain)\n",
        "\n",
        "# 3) USR del ligando (positivos)\n",
        "df_usr_lig_pos = df_ligand_smiles_USR.copy()\n",
        "df_usr_lig_pos['instancia'] = df_usr_lig_pos['instancia'] + '_positive'\n",
        "df_usr_lig_pos = df_usr_lig_pos.rename(columns={f'USR_{i}': f'USR_{i}_ligando' for i in range(1, 13)})\n",
        "\n",
        "# 4) USR del sitio (base, sin suffix aún)\n",
        "df_usr_site = df_usr_sitio.copy()\n",
        "df_usr_site = df_usr_site.rename(columns={\n",
        "    'instacia': 'instancia',\n",
        "    **{f'USR_{i}': f'USR_{i}_sitio' for i in range(1, 13)}\n",
        "})\n",
        "\n",
        "# 5) Construir DataFrames base para concatenar\n",
        "lig_cols   = [f'USR_{i}_ligando' for i in range(1, 13)]\n",
        "base_cols  = ['instancia', 'PDB_chain', 'Ligand_smiles', 'Label'] + lig_cols\n",
        "\n",
        "# Positivos: merge con USR ligando\n",
        "df_pos_base = (\n",
        "    df_pos2[['instancia', 'PDB_chain', 'Ligand_smiles', 'Label']]\n",
        "    .merge(\n",
        "        df_usr_lig_pos[['instancia', 'Ligand_smiles'] + lig_cols],\n",
        "        on=['instancia', 'Ligand_smiles'],\n",
        "        how='left'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Negativos: ya tienen columnas USR_ligando\n",
        "df_neg_base = df_neg2[base_cols]\n",
        "\n",
        "# Concatenar positivos y negativos\n",
        "df_main = pd.concat([df_pos_base, df_neg_base], ignore_index=True)\n",
        "\n",
        "# 6) Añadir embeddings del ligando\n",
        "df_emb_lig = df_emb_ligandos.copy()\n",
        "df_emb_lig = df_emb_lig.rename(columns={str(i): f'emb_lig_{i}' for i in range(128)})\n",
        "df_main = df_main.merge(\n",
        "    df_emb_lig[['instancia'] + [f'emb_lig_{i}' for i in range(128)]],\n",
        "    on='instancia', how='left'\n",
        ")\n",
        "\n",
        "# 7) Añadir embeddings de la proteína\n",
        "df_emb_prot = df_emb_proteinas.copy()\n",
        "df_emb_prot = df_emb_prot.rename(columns={\n",
        "    'Unnamed: 0': 'PDB_entry_id',\n",
        "    **{str(i): f'emb_prot_{i}' for i in range(320)}\n",
        "})\n",
        "df_emb_prot['PDB_chain'] = (\n",
        "    df_emb_prot['PDB_entry_id'].str[:4].str.upper() + '_' +\n",
        "    df_emb_prot['PDB_entry_id'].str[5:6]\n",
        ")\n",
        "df_emb_prot = df_emb_prot.drop(columns=['PDB_entry_id'])\n",
        "df_main = df_main.merge(df_emb_prot, on='PDB_chain', how='left')\n",
        "\n",
        "# 8) Añadir USR del sitio usando el nombre base de instancia\n",
        "# Creamos columna auxiliar 'inst_base' sin sufijo\n",
        "df_main['inst_base'] = (\n",
        "    df_main['instancia']\n",
        "        .str.replace('_positive', '', regex=False)\n",
        "        .str.replace('_negative', '', regex=False)\n",
        ")\n",
        "# Para df_usr_site también\n",
        "df_usr_site['inst_base'] = df_usr_site['instancia']\n",
        "\n",
        "usr_site_cols = [f'USR_{i}_sitio' for i in range(1, 13)]\n",
        "df_main = df_main.merge(\n",
        "    df_usr_site[['inst_base'] + usr_site_cols],\n",
        "    on='inst_base', how='left'\n",
        ")\n",
        "df_main = df_main.drop(columns=['inst_base'])\n",
        "\n",
        "# 9) Limpiar sufijos _x/_y y eliminar duplicados\n",
        "df_main.columns = (\n",
        "    df_main.columns\n",
        "        .str.replace(r'_x$', '', regex=True)\n",
        "        .str.replace(r'_y$', '', regex=True)\n",
        ")\n",
        "df_main = df_main.loc[:, ~df_main.columns.duplicated()]\n",
        "\n",
        "# 10) Filtrar columnas finales esperadas\n",
        "final_cols = (\n",
        "    ['instancia', 'Label'] +\n",
        "    [f'emb_lig_{i}' for i in range(128)] +\n",
        "    [f'emb_prot_{i}' for i in range(320)] +\n",
        "    lig_cols +\n",
        "    usr_site_cols\n",
        ")\n",
        "df_main = df_main[[c for c in final_cols if c in df_main.columns]]\n",
        "\n",
        "# 11) Verificación final\n",
        "print(f\"df_main final: {df_main.shape[0]} filas × {df_main.shape[1]} columnas\")\n",
        "print(\"NaNs en USR_sitio tras merge:\",\n",
        "      df_main[usr_site_cols].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l758YnVFZx4",
        "outputId": "3af54ef7-8c65-4e43-a1db-ecd2d5c041ed",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ df_main final: 140606 filas × 474 columnas\n",
            "NaNs en USR_sitio tras merge: USR_1_sitio     28\n",
            "USR_2_sitio     28\n",
            "USR_3_sitio     28\n",
            "USR_4_sitio     28\n",
            "USR_5_sitio     28\n",
            "USR_6_sitio     28\n",
            "USR_7_sitio     28\n",
            "USR_8_sitio     28\n",
            "USR_9_sitio     28\n",
            "USR_10_sitio    28\n",
            "USR_11_sitio    28\n",
            "USR_12_sitio    28\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = df_main.dropna()"
      ],
      "metadata": {
        "id": "-VVwRf77FdDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mhnhCnSFeaQ",
        "outputId": "046d5bea-9ee1-4574-a115-4f30b3f200b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140348, 474)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.to_csv(\"/content/drive/MyDrive/TFM/T3/Archivos/df_tot_pos_neg_usr_emb_prot_liga_preentrenado.csv\")"
      ],
      "metadata": {
        "id": "JSEq9rfGFf44"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}