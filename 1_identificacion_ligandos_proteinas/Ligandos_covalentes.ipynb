{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCMFMXqx2OXy",
        "outputId": "8827a912-06c4-4fe2-caf7-6d3db0c469a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Ln0-yL2dVi",
        "outputId": "82ab9f2e-99b5-4bdf-d3b5-b9c060018576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110850 Index(['PDB_entry_id', 'Classification', 'Organism', 'Uniprot_id', 'Ligand_id',\n",
            "       'Ligand_InChi', 'Experimental_method', 'Resolution',\n",
            "       'Adding_Classification', 'Affinity', 'Kd/Ki'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#@title Abrir el dataframe\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/TMF/T1/ENLACE_COVALENTE\"\n",
        "input_file = os.path.join(input_folder, \"df_harm_affinity.csv\")\n",
        "df_harm = pd.read_csv(input_file, sep = ',')\n",
        "print(df_harm.shape[0],df_harm.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzVq31gW3VDg",
        "outputId": "a7ef302e-d7b2-4546-ee64-de73c8dac382",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdbecif\n",
            "  Downloading PDBeCif-1.5-py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading PDBeCif-1.5-py3-none-any.whl (48 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdbecif\n",
            "Successfully installed pdbecif-1.5\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting Biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Biopython) (1.26.4)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Biopython\n",
            "Successfully installed Biopython-1.85\n"
          ]
        }
      ],
      "source": [
        "#@title installar librerías\n",
        "\n",
        "!pip install pdbecif\n",
        "!pip install pandas\n",
        "!pip install Biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZmJf-te3Vtw",
        "outputId": "dcc379c0-12a0-43fa-b1a3-171d608e5a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDB-CAT installed\n"
          ]
        }
      ],
      "source": [
        "#@title Crear los directorios y clonar el repositorio GitHub\n",
        "import os\n",
        "\n",
        "repo_path = \"/content/drive/MyDrive/TMF/T1/ENLACE_COVALENTE\"\n",
        "\n",
        "# Check if the PDB-CAT repository has been cloned and installed\n",
        "if not os.path.isfile(\"PDB-CAT_READY\"):\n",
        "    os.system(\"git clone https://github.com/URV-cheminformatics/PDB-CAT.git\")\n",
        "    os.chdir(repo_path)  # Change directory to the cloned repository\n",
        "    os.system(\"pip install -r requirements.txt\")  # Install PDB-CAT if it has a setup.py or pyproject.toml\n",
        "    os.chdir(\"/content\")  # Change back to the original directory\n",
        "    os.system(\"touch PDB-CAT_READY\")  # Create the PDB-CAT_READY file to indicate successful cloning and installation\n",
        "print(\"PDB-CAT installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjDQqQOI3gEY",
        "outputId": "200dcb60-c699-4b63-fc39-6d32c60c4bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorios creados o ya existentes: /content/drive/MyDrive/TMF/T1/ENLACE_COVALENTE/PDB-CAT/PDB-CAT/cif /content/drive/MyDrive/TMF/T1/ENLACE_COVALENTE/PDB-CAT/PDB-CAT/out\n"
          ]
        }
      ],
      "source": [
        "#@title Definir carpetas de input y de output\n",
        "\n",
        "import os\n",
        "\n",
        "# Definir la carpeta base correctamente\n",
        "github = \"/content/drive/MyDrive/TMF/T1/ENLACE_COVALENTE/PDB-CAT/PDB-CAT\"\n",
        "\n",
        "def ensure_directories():\n",
        "    # Crear rutas correctamente\n",
        "    cif_dir = os.path.join(github, \"cif\")\n",
        "    out_dir = os.path.join(github, \"out\")\n",
        "\n",
        "    # Crear directorios si no existen\n",
        "    os.makedirs(cif_dir, exist_ok=True)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Directorios creados o ya existentes:\", cif_dir, out_dir)\n",
        "\n",
        "ensure_directories()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GSpCsSS3mho"
      },
      "outputs": [],
      "source": [
        "#@title Import librarias\n",
        "\n",
        "from pdbecif.mmcif_io import CifFileReader\n",
        "from pdbecif.mmcif_tools import MMCIF2Dict\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "from Bio.Align import PairwiseAligner\n",
        "from Bio.PDB import *\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import sys\n",
        "sys.path.append('/content/PDB-CAT')\n",
        "from PDBCAT_module import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SLb685IZT_u"
      },
      "outputs": [],
      "source": [
        "#@title Definir las rutas de las carpetas\n",
        "\"\"\"\n",
        "=========\n",
        "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
        "\"\"\"\n",
        "reference = ''\n",
        "\n",
        "directory_path = github + \"/cif/9/\"  # Path to the folder with the cif files to process\n",
        "output_path = github + \"/out/\"                                 # Path for the new categorizing folders\n",
        "out_file = output_path + \"df.csv\"                             # Path and name of the FIRST csv output file (protein-centered) (.csv)\n",
        "out_file_ligands = output_path + \"df_ligands.csv\"             # Path and name of the SECOND csv output file (ligand-centered) (.csv)\n",
        "mutation = False                                              # Analyze mutations. True or False\n",
        "pdb_reference_sequence = directory_path + reference           # Path to the pdb file that will be the reference sequence.\n",
        "entity_reference = 0                                          # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
        "res_threshold = 15                                            # Chose a threshold to discriminate between peptides and the subunits of the protein\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB74VPmiVKO5"
      },
      "outputs": [],
      "source": [
        "#@title MAIN CODE\n",
        "\"\"\"\n",
        "MAIN CODE. YOU DO NOT NEED TO CHANGE THIS PART\n",
        "\"\"\"\n",
        "blacklist, blacklist_dict = read_blacklist(\"/content/PDB-CAT/blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
        "\n",
        "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
        "reference_seq=''\n",
        "if mutation == True:\n",
        "    ref_cfr = CifFileReader()\n",
        "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
        "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
        "    if '_entity_poly' in ref_cif_data:\n",
        "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]\n",
        "        reference_seq = reference_seq.replace(\"\\n\",\"\")\n",
        "\n",
        "# First csv output. Protein-centered\n",
        "# Second csv output. Ligand-centered\n",
        "\n",
        "data = []\n",
        "data_ligands = []\n",
        "fields_to_include = [\"PDB_ID\", \"Ligand\", \"Ligand_names\",\"Ligand_types\", \"Ligand_functions\", \"Covalent_Bond\", \"Bond\"]\n",
        "fields_to_append = [\"PDB_ID\"]\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith('.cif'):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq, res_threshold)\n",
        "        data.append(data_from_file)\n",
        "\n",
        "        # Split ligand names and create a new row for each ligand\n",
        "        ligands = data_from_file[\"Ligand\"].split('\\n')\n",
        "        ligand_names_list = data_from_file[\"Ligand_names\"].split('\\n')\n",
        "        ligand_types_list = data_from_file[\"Ligand_types\"].split('\\n')\n",
        "        covalent_bond_list = data_from_file[\"Covalent_Bond\"].split('\\n')\n",
        "        ligand_covalents_bond = data_from_file[\"Bond\"].split('\\n')\n",
        "        descarted_ligands = data_from_file[\"Discarted_Ligands\"].split('\\n')\n",
        "\n",
        "\n",
        "        # Find the maximum length among the three lists\n",
        "        max_length = max(len(ligands), len(ligand_names_list), len(ligand_types_list), len(covalent_bond_list), len(ligand_covalents_bond), len(descarted_ligands))\n",
        "\n",
        "        for i in range(max_length):\n",
        "            ligand_row = {field: data_from_file[field] for field in fields_to_include}\n",
        "\n",
        "            # Get the element from each list\n",
        "            ligand_row[\"Ligand\"]= ligands[i].strip() if i < len(ligands) else \"\"\n",
        "            ligand_row[\"Ligand_names\"] = ligand_names_list[i].strip() if i < len(ligand_names_list) else \"\"\n",
        "            ligand_row[\"Ligand_types\"] = ligand_types_list[i].strip() if i < len(ligand_types_list) else \"\"\n",
        "            ligand_row[\"Covalent_Bond\"] = covalent_bond_list[i].strip() if i < len(covalent_bond_list) else \"\"\n",
        "            ligand_row[\"Bond\"] = ligand_covalents_bond[i].strip() if i < len(ligand_covalents_bond) else \"\"\n",
        "            data_ligands.append(ligand_row)\n",
        "\n",
        "\n",
        "            # Add column to the ligands DataFrame and fill it with corresponding information\n",
        "            if i < len(descarted_ligands) and descarted_ligands[i].strip():  # Ensure there is information before adding\n",
        "                ligand_row_discarded = {field: data_from_file[field] for field in fields_to_include}\n",
        "                ligand_row_discarded[\"Ligand\"] = descarted_ligands[i].strip()\n",
        "                ligand_row_discarded[\"Ligand_names\"] = blacklist_dict[descarted_ligands[i].strip()]\n",
        "                ligand_row_discarded[\"Ligand_types\"] = \"Discarded\"\n",
        "                ligand_row_discarded[\"Covalent_Bond\"] = \"\"\n",
        "                ligand_row_discarded[\"Bond\"] = \"\"\n",
        "                data_ligands.append(ligand_row_discarded)\n",
        "\n",
        "\n",
        "# First csv output. Protein-centered\n",
        "df = pd.DataFrame(data)  # Create a Pandas df\n",
        "df.to_csv(out_file, index=False)  # Save the df into a file\n",
        "\n",
        "# Second csv output. Ligand-centered\n",
        "df_ligand = pd.DataFrame(data_ligands) # Create a Pandas df\n",
        "\n",
        "# Remove rows where 'Ligand' is empty or contains only white spaces\n",
        "df_ligand['Ligand'] = df_ligand['Ligand'].str.strip()\n",
        "df_ligand = df_ligand[df_ligand['Ligand'] != '']\n",
        "\n",
        "# Define the new names for the columns\n",
        "new_header = ['ID', 'Molecule', 'Name', 'Type', 'Function', 'Covalent', 'Bond']\n",
        "df_ligand.columns = new_header\n",
        "\n",
        "# Second csv output. Ligand-centered\n",
        "df_ligand.to_csv(out_file_ligands, index=False) # Save the df into a file\n",
        "\n",
        "# Classify whether there is a mutation\n",
        "if mutation == False:\n",
        "    no_mutated_list = os.listdir(directory_path)\n",
        "    no_mutated_list = [filename[:-4] for filename in no_mutated_list]\n",
        "\n",
        "if mutation ==True:\n",
        "    no_mutated_list, non_mut_path = mutation_classification(directory_path, out_file, output_path)\n",
        "    output_path = non_mut_path\n",
        "\n",
        "# Classify depend on the bond\n",
        "#bond_classification(directory_path, out_file, no_mutated_list, output_path, mutation)"
      ]
    }
  ]
}